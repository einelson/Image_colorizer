{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Image Colorization</h1>\n",
    "<p>This is our experimantation on using TensorFlow to predict colored images from black and white</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage.color import lab2rgb, rgb2lab\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, InputLayer, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import (array_to_img, img_to_array,load_img)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get L value (this is our X)\n",
    "def get_lab(img):\n",
    "    l = rgb2lab(img/255)[:,:,0]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get A & B values (this is our Y)\n",
    "def get_color(img):\n",
    "    x = rgb2lab(img/255)[:,:,1:] # this is the A and B values; a-magenta-green; b-yellow-blue\n",
    "    x/=128\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this uploads our images\n",
    "def get_images(path, color=\"lab\"):\n",
    "    images = list()\n",
    "    for filename in os.listdir(path):\n",
    "        if filename[0] != '.':\n",
    "            if color == \"lab\":\n",
    "                img = get_lab(np.array(img_to_array(load_img(path + filename)), dtype=float))\n",
    "                images.append(img.reshape(1,img.shape[0],img.shape[1],1))\n",
    "            else:\n",
    "                img = get_color(np.array(img_to_array(load_img(path + filename)), dtype=float))\n",
    "                images.append(img.reshape(1,img.shape[0],img.shape[1],2))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522\n",
      "WARNING:tensorflow:From C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, None, None, 8)     80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 16)    1168      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 16)    2320      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 32)    4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 16)    4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, None, None, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 2)     290       \n",
      "=================================================================\n",
      "Total params: 31,618\n",
      "Trainable params: 31,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 5/10000 [03:27<115:30:56, 41.61s/it]ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-3eae066b4e29>\", line 45, in <module>\n",
      "    model.fit(x=x[i],y=y[i], batch_size=50,verbose=0, epochs=1)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\einel\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Convert all training images from the RGB color space to the Lab color space.\n",
    "Use the L channel as the input to the network and train the network to predict the ab channels.\n",
    "Combine the input L channel with the predicted ab channels.\n",
    "Convert the Lab image back to RGB.\n",
    "'''\n",
    "x = get_images(\"./OurTrainingImages/\") #l value only\n",
    "print(len(x))\n",
    "y = get_images(\"./OurTrainingImages/\", color=\"yes\") #a and b values\n",
    "\n",
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "# model = tf.keras.models.load_model('./img_predictions/model.h5')\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None, None, 1))) # input shape is only needed for first layer? input_shape=(256, 256, 3)\n",
    "# 3x3 kernel used and 8 filters?\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "# figure out what this does\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3,3), activation='tanh', padding='same'))\n",
    "# get working after we get NN working better\n",
    "'''\n",
    "# supposed to soften image\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "'''\n",
    "# get summary of layers and compile\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='mse') # loss='sparse_categorical_crossentropy', optomizer='rmsprop'\n",
    "\n",
    "\n",
    "# there is an issue fitting the data\n",
    "for e in tqdm(range(10000)):\n",
    "    for i,j in enumerate(x):\n",
    "        model.fit(x=x[i],y=y[i], batch_size=50,verbose=0, epochs=1)\n",
    "\n",
    "# evaluate model\n",
    "# model.evaluate(x, y, batch_size=1)\n",
    "\n",
    "# save model\n",
    "model.save('./img_predictions/model.h5') \n",
    "\n",
    "\n",
    "#Load test images\n",
    "test_images = get_images(\"./OurTrainingImages/\")\n",
    "# print(len(test_images))\n",
    "\n",
    "for i,z in enumerate(test_images):\n",
    "    # make predictions\n",
    "    output = model.predict(z)\n",
    "    output*=128\n",
    "    cur = np.zeros((256,256,3))\n",
    "    cur[:,:,0] = z[:,:,0] # L layer?\n",
    "    cur[:,:,1:] = output[0] # A B layers?\n",
    "    rgb_image = lab2rgb(cur)\n",
    "\n",
    "    img = array_to_img(rgb_image)\n",
    "    img.save(\"./img_predictions/{}.jpg\".format(i))\n",
    "    img.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
