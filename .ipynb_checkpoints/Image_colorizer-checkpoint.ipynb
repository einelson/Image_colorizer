{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Image Colorization</h1>\n",
    "<h2>Team Members</h2>\n",
    "<p>\n",
    "    Eli Harris, Tristan Fullmer, Ethan Nelson\n",
    "</p>\n",
    "\n",
    "<h2>Introduction</h2>\n",
    "<p>\n",
    "A quick google search reveals that colored photography began in the 1860s. The quality\n",
    "and use of taking colored images continued to progress over time. Likewise, the first colored\n",
    "film came out in the early 20th century. However black and white films continued to be produced\n",
    "even after the 1950s.<br>\n",
    "Many black and white photos would give one additional insight by providing the colored\n",
    "complement. One example is old family history photos. Although the black and white image\n",
    "gives some information, it is missing important details such as hair and eye color. We use a\n",
    "neural network machine learning algorithm to ‘colorize’ the black and white images.\n",
    "We used images from several repositories including the following:<br>\n",
    "https://www.floydhub.com/emilwallner/datasets/colornet/2/images,\n",
    "https://unsplash.com/collections\n",
    "The floydhub repository has both black and white and colored images for the training\n",
    "and test sets. We augmented these sets with additional images from the unsplash repository.\n",
    "From the unsplash repository, we obtain images from a variety of themes to diversify the types\n",
    "of images we train on. Some of the themes include:<br>\n",
    "● Winter: Mostly white images with some color<br>\n",
    "● Happiness: bright colorful images with lots of colors<br>\n",
    "● Moody: dark black/greyish images with a little color<br>\n",
    "● OneColor: images that have mostly one color<br>\n",
    "● Neon: images that are filled with bright neon colors<br>\n",
    "By diversifying the training set, we expected to obtain better results. \n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<h2>Data Preperation</h2>\n",
    "<p>\n",
    "    In order to pre-process our data, we need to get the RGB values out of the image then\n",
    "convert the RGB values to LAB. This is important because the LAB separates the color from the\n",
    "black and white. By removing the color we are able to create a testing and training sets.\n",
    "The algorithm we are using was designed to take photos that are 256 by 256 pixels.<br>\n",
    "Rather than generalize the code to fit any sized picture, we decided to scale and crop the\n",
    "photos. We used InfranView64 to scale and crop the photos to the correct size for the algorithm.\n",
    "There are several reasons to scale and crop the photos rather than generalizing the algorithm to\n",
    "take in any size photos. The foremost reason is that bigger photos add a significantly larger\n",
    "computational cost than the scaled ones. Additionally, the scaled photos do not significantly\n",
    "reduce the information of the data.<br>\n",
    "Our dataset is non-trivial in a few ways, one being the fact that the values are stored in a\n",
    "3D array. Neural networks, at least to our understanding, are not easily able to handle 3D\n",
    "arrays. One way we are going to try to overcome this is to convert our data to a 2D array or a\n",
    "vector then revert the results back to a 3D array\n",
    "</p>\n",
    "\n",
    "<h2>Mining/ learning from the data</h2>\n",
    "<p>\n",
    "In order to learn patterns from our data, we had to find images with the same number of\n",
    "data points, meaning that they were the same size. While researching image processing we\n",
    "found out that Convolutional Neural Networks (CNN) seemed most common and efficient. The\n",
    "reason behind this is because a CNN can take in a three-dimensional object, find patterns in\n",
    "each layer and use that to predict a single layer. In short, we were trying to take a onedimensional array and use that layer to predict a second and third layer. The way that neural\n",
    "networks work is that they use weights, meaning we can have a weight for every layer or input\n",
    "or output, etc, and in short it is easier to train a series of weights on an array rather than a\n",
    "singular algorithm on every single data point in the array. The parameters that we used included\n",
    "how many times that we trained the weights (epochs), the size of the image and the activation\n",
    "functions.<br>\n",
    "The first thing that we have tried is converting our data into a 2d array, however, it has\n",
    "not been working too well. In the end, we did get the images to convert to arrays and train the\n",
    "network on that. We tried a few different approaches to how we set up our CNN. they way that\n",
    "CNNs work makes them very particular in how you add the layers and how your model is put\n",
    "together. Training a CNN also is very time consuming and computationally expensive. We tried\n",
    "a few approaches into saving our weights, one saving them in binary and another using h5,\n",
    "which is python’s standard library.<br>\n",
    "The biggest challenge that we faced was getting the neural network to correctly predict a\n",
    "colorized image. It was difficult to get the network to predict itself, we grayscaled an image and\n",
    "used that as training and testing data. After that, because there are such a variety of colors, \n",
    "shades, and brightnesses that it was immensely difficult to train a CNN on a dataset of that size.\n",
    "In our training set we used about 550 images and tested them at 10,000 epochs, or cycles it\n",
    "takes eight to nine hours on a GPU to run each test.\n",
    "\n",
    "</p>\n",
    "\n",
    "<h2>Results</h2>\n",
    "<p>\n",
    "We successfully implemented a neural network that imports and exports images. However, as\n",
    "shown below, the resulting algorithm predictions are underwhelming. The CNN was able to add\n",
    "some color here or there but the CNN colored images are hardly recognizable with their black\n",
    "and white input image.\n",
    "</p>\n",
    "\n",
    "<h2>Conclusions</h2>\n",
    "<p>\n",
    "Our results could have a number of applications. The first and most obvious would be\n",
    "for historical organizations to be able to view old black and white pictures in color. If this concept\n",
    "were taken and applied to video, we could achieve two things, it could be used on nighttime\n",
    "security cameras to be able to see in full color even at night time as well as using this to colorize\n",
    "black and white movies. The last application is training on an image with a certain color schema\n",
    "and using that as a filter to create other images with the same color scheme. As a result of our \n",
    "work, we feel that business owners in our surrounding area would have something more to offer\n",
    "the community. There are many businesses whose main purpose is family history. It would be a\n",
    "great opportunity for these businesses to offer a colorized version of a black and white photo\n",
    "taken of a deceased great grandparent or perhaps an ancestor.<br>\n",
    "Our results are very interesting. As described earlier, our network can only perform as\n",
    "well as the images trained on, and as there are a great variety of colors and shades we do not\n",
    "have the image dataset, or the time (as data could be gathered) to train a network being\n",
    "capable of correctly predicting a random image 100%. Some of our images ended up with\n",
    "random colors, as we did not have the correct shade trained, and some ended up as blobs of\n",
    "color are just being the silhouette of the image.<br>\n",
    "One ethical issue is discussing how far you can take the validity of computer coloring. If\n",
    "a security camera is used as evidence of a crime, and the color of something is important, it\n",
    "raises the question of the court’s level of trust in the computer’s prediction.\n",
    "</p>\n",
    "\n",
    "\n",
    "<h2>Lessons Learned</h2>\n",
    "<p>\n",
    "One thing that we learned from this project was the complexity of Convolutional Neural\n",
    "Networks and the spaces that it uses. There are a lot of concepts that go into CNNs and they\n",
    "are difficult to compose. You can create a CNN to find vertical or horizontal lines. You can use\n",
    "them to classify text. It was interesting to learn how rearranging the layers can change the\n",
    "whole model, even if you are using the same images.<br>\n",
    "If we had the opportunity to redo this project we would try to make our algorithm training\n",
    "more efficient. We are using Keras and tensorflow to run our network and it would have been\n",
    "nice to have additional time in research to find a more efficient way to run our algorithm. For\n",
    "example, we are iterating through a list and training on the arrays inside of it, but if we put our\n",
    "images together into a massive array then we might be able to train on all of the data all at once\n",
    "rather than individually.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
